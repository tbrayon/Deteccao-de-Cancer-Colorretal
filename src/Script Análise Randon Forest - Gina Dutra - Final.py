import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency
from scipy.stats import spearmanr
import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.feature_selection import mutual_info_classif
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import SMOTE


# Set global style for plots
sns.set_palette("husl")
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 100

# Make output dirs if they don't exist
os.makedirs("graphs", exist_ok=True)
os.makedirs("csv", exist_ok=True)
os.makedirs("cluster_graphs", exist_ok=True)

# Conectar o Google Drive ao ambiente do Colab.
# drive.mount('/content/drive')

# Defina o caminho correto para o arquivo no Google Colab
file_path = "c:/Users/gina_/OneDrive/√Årea de Trabalho/PUC/AULAS 7 SEMESTRE/Projeto/Projeto/Etapa 3/colorectal_cancer_prediction_csv.csv"

# Carregar o dataset diretamente usando pandas
df = pd.read_csv(file_path)

df = df.drop(columns=['Patient_ID'])

# Separate features and targets
targets = ['Survival_Status']
features = df.drop(columns=targets)

# Define preprocessing pipeline
numeric_features = features.select_dtypes(include=np.number).columns.tolist()
categorical_features = features.select_dtypes(exclude=np.number).columns.tolist()

print("Start of data transformation...")

numeric_transformer = Pipeline(steps=[
	('imputer', SimpleImputer(strategy='median')),
	('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
	('imputer', SimpleImputer(strategy='most_frequent')),
	('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
	transformers=[
    	('num', numeric_transformer, numeric_features),
    	('cat', categorical_transformer, categorical_features)])

# Fit and transform the data
preprocessed_data = preprocessor.fit_transform(features)

# Get feature names after preprocessing
numeric_names = numeric_features
categorical_names = preprocessor.named_transformers_['cat'].named_steps['onehot']\
                 	.get_feature_names_out(categorical_features)
all_feature_names = np.concatenate([numeric_names, categorical_names])

# Convert to DataFrame for analysis (if sparse matrix)
if hasattr(preprocessed_data, "toarray"):
	preprocessed_df = pd.DataFrame(preprocessed_data.toarray(), columns=all_feature_names)
else:
	preprocessed_df = pd.DataFrame(preprocessed_data, columns=all_feature_names)

print("End of data transformation...")

# Separa√ß√£o entre features (X) e target (y)
# Separa√ß√£o de Dados: Os dados s√£o divididos entre X (features) e y (target, no caso a sobreviv√™ncia).
# Dados tratados
# Define X como os dados que foram pr√©-processados no c√≥digo anterior.
X = preprocessed_df
# Convers√£o da Target: Transformamos "Survived" em 1 e "Deceased" em 0.
# Converte a vari√°vel alvo ("Survived" ‚Üí 1 e "Deceased" ‚Üí 0) para valores num√©ricos.
y = df['Survival_Status'].replace({'Survived': 1, 'Deceased': 0}).infer_objects(copy=False)

# Divis√£o dos dados em treinamento (80%) e teste (20%)
# Divis√£o do Dataset: O dataset √© dividido em treinamento (80%) e teste (20%) para avaliar o desempenho dos modelos.
# Treinamento dos Modelos: Cada modelo recebe os dados de treinamento (X_train, y_train) e aprende padr√µes para fazer previs√µes.
# Divide os dados em: 80% treino ‚Üí usados para ensinar os modelos. 20% teste ‚Üí usados para validar os modelos.
# Garante que a divis√£o seja reprodut√≠vel (os mesmos conjuntos sempre que o c√≥digo for executado).
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"N√∫mero de linhas em X_train: {X_train.shape[0]}")
print(f"N√∫mero de colunas em X_train: {X_train.shape[1]}")

print(f"N√∫mero de linhas em X_test: {X_test.shape[0]}")
print(f"N√∫mero de colunas em X_test: {X_test.shape[1]}")


# ----------------------
# 1. AN√ÅLISE RANDON FOREST, MODELO XGBBOOST E MODELO BAYES
# ----------------------

# 1Ô∏è‚É£ Modelo Random Forest
# Cria um modelo Random Forest com 100 √°rvores.
# O Random Forest √© um algoritmo baseado em m√∫ltiplas √°rvores de decis√£o. Cada √°rvore aprende um pequeno aspecto dos dados e, no final, todas as √°rvores juntas fazem uma vota√ß√£o para dar uma previs√£o mais robusta.
# üîπ Mais √°rvores = mais estabilidade Quando o modelo tem poucas √°rvores, ele pode ter mais varia√ß√µes e ser sens√≠vel a mudan√ßas nos dados. Com mais √°rvores, ele generaliza melhor, reduzindo o risco de tomar decis√µes erradas devido a dados
# espec√≠ficos do treino.
# üîπ Aprimora a precis√£o Geralmente, aumentar o n√∫mero de √°rvores melhora a precis√£o, pois cada √°rvore traz uma perspectiva diferente sobre os dados.
# üîπ Compromisso entre desempenho e tempo de execu√ß√£o Testes pr√°ticos mostram que 100 √°rvores √© um bom n√∫mero para equilibrar qualidade e velocidade.
# Se tivermos milhares de √°rvores, o treinamento pode ficar muito lento sem ganhos significativos na precis√£o.
# O Bagging ocorre quando est√° sendo instanciado um modelo RandomForestClassifier com n_estimators=100, ou seja, 100 √°rvores de decis√£o ser√£o treinadas usando
# subconjuntos aleat√≥rios do seu dataset.
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
# Treina o modelo nos dados de treino.
# O Random Forest tamb√©m aplica Feature Selection automaticamente ao treinar o modelo (rf_model.fit(X_train, y_train)).
# Ele seleciona aleatoriamente um subconjunto de atributos para cada √°rvore, reduzindo a depend√™ncia de atributos irrelevantes
rf_model.fit(X_train, y_train)
# Obter import√¢ncia das features (Feature Selection)
feature_importances = rf_model.feature_importances_
# Ordenar e visualizar
indices = np.argsort(feature_importances)[::-1]  # Ordena do maior para o menor
plt.figure(figsize=(30, 20))
plt.title("Import√¢ncia das Features no Random Forest")
plt.barh(range(X_train.shape[1]), feature_importances[indices])
plt.yticks(range(X_train.shape[1]), np.array(all_feature_names)[indices])
plt.gca().invert_yaxis()  # Opcional: coloca a feature mais importante no topo
plt.xlabel("Import√¢ncia")
plt.ylabel("Features")
plt.show()
# Faz previs√µes no conjunto de teste.
rf_pred = rf_model.predict(X_test)

# Matriz de Confus√£o para Random Forest
# Ela compara os valores reais (y_test) com os valores preditos (rf_pred) pelo modelo Random Forest.
cm_rf = confusion_matrix(y_test, rf_pred)
# Cria uma nova √°rea de figura do matplotlib, definindo o tamanho dela: 8 de largura por 6 de altura.
plt.figure(figsize=(8, 6))
# sns.heatmap √© a fun√ß√£o do Seaborn que desenha uma mapa de calor (heatmap).
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Deceased', 'Survived'], yticklabels=['Deceased', 'Survived'])
# Define o t√≠tulo do eixo X como "Valores Previstos".
plt.xlabel('Valores Previstos')
# Define o t√≠tulo do eixo Y como "Valores Reais".
plt.ylabel('Valores Reais')
# Define o t√≠tulo do gr√°fico.
plt.title('Matriz de Confus√£o: Random Forest')
# Exibe o gr√°fico na tela.
plt.show()

# 2Ô∏è‚É£ Modelo XGBoost
# Cria um modelo XGBoost.
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
# Treina o modelo com os dados de treino.
xgb_model.fit(X_train, y_train)
xgb_importances = xgb_model.feature_importances_
indices = np.argsort(xgb_importances)[::-1]

plt.figure(figsize=(30, 20))
plt.title("Import√¢ncia das Features no XGBoost")
plt.barh(range(X_train.shape[1]), xgb_importances[indices])
plt.yticks(range(X_train.shape[1]), np.array(all_feature_names)[indices])
plt.gca().invert_yaxis()
plt.xlabel("Import√¢ncia")
plt.ylabel("Features")
plt.show()
# Faz previs√µes no conjunto de teste.
xgb_pred = xgb_model.predict(X_test)

# Matriz de Confus√£o para XGBoost
cm_xgb = confusion_matrix(y_test, xgb_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Deceased', 'Survived'], yticklabels=['Deceased', 'Survived'])
plt.xlabel('Valores Previstos')
plt.ylabel('Valores Reais')
plt.title('Matriz de Confus√£o: XGBoost')
plt.show()

# 3Ô∏è‚É£ Modelo Naive Bayes
# Cria um modelo Naive Bayes baseado na distribui√ß√£o normal.
nb_model = GaussianNB()
# Treina o modelo com os dados de treino.
nb_model.fit(X_train, y_train)
# Obtemos as m√©dias das features para cada classe
means = nb_model.theta_  # shape: (n_classes, n_features)

# Calculamos a diferen√ßa absoluta entre as m√©dias das classes
# Para problemas bin√°rios, podemos fazer isso assim:
mean_diff = np.abs(means[1] - means[0])

# Ordena as features pela diferen√ßa
indices = np.argsort(mean_diff)[::-1]

# Plota as diferen√ßas como "import√¢ncias"
plt.figure(figsize=(30, 20))
plt.title("Diferen√ßa entre m√©dias das classes (interpreta√ß√£o de import√¢ncia) - Naive Bayes")
plt.barh(range(X_train.shape[1]), mean_diff[indices])
plt.yticks(range(X_train.shape[1]), np.array(all_feature_names)[indices])
plt.gca().invert_yaxis()
plt.xlabel("Diferen√ßa entre m√©dias")
plt.ylabel("Features")
plt.show()
# Faz previs√µes no conjunto de teste.
nb_pred = nb_model.predict(X_test)

# Matriz de Confus√£o para Naive Bayes
cm_nb = confusion_matrix(y_test, nb_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Oranges',
            xticklabels=['Deceased', 'Survived'], yticklabels=['Deceased', 'Survived'])
plt.xlabel('Valores Previstos')
plt.ylabel('Valores Reais')
plt.title('Matriz de Confus√£o: Naive Bayes')
plt.show()

# Fun√ß√£o para calcular e exibir as m√©tricas
# Avalia√ß√£o dos Modelos: O c√≥digo mede o desempenho dos tr√™s modelos usando as m√©tricas: üîπ Acur√°cia (quantidade de previs√µes corretas) üîπ Precis√£o (qu√£o correto √© quando prev√™ sobreviv√™ncia)
# üîπ Recall (quantos casos de sobreviv√™ncia foram corretamente identificados) üîπ F1-score (m√©dia harm√¥nica entre precis√£o e recall)
# Define uma fun√ß√£o evaluate_model(name, y_test, y_pred), que recebe: name ‚Üí Nome do modelo. // y_test ‚Üí Verdadeiro status de sobreviv√™ncia. // y_pred ‚Üí Previs√µes do modelo.
# Calcula e exibe as m√©tricas de desempenho: Acur√°cia ‚Üí Percentagem de previs√µes corretas. // Precis√£o ‚Üí Qu√£o correto √© quando prev√™ sobreviv√™ncia. // Recall ‚Üí Quantos casos de sobreviv√™ncia foram identificados corretamente.
# F1-score ‚Üí Combina√ß√£o entre precis√£o e recall.
def evaluate_model(name, y_test, y_pred):
    print(f"\nResultados para {name}:")
    print(f"Acur√°cia: {accuracy_score(y_test, y_pred):.4f}")
    print(f"Precis√£o: {precision_score(y_test, y_pred):.4f}")
    print(f"Recall: {recall_score(y_test, y_pred):.4f}")
    print(f"F1-Score: {f1_score(y_test, y_pred):.4f}")

# Avalia√ß√£o dos modelos
# Chama a fun√ß√£o evaluate_model para cada modelo, imprimindo os resultados das m√©tricas.
evaluate_model("Random Forest", y_test, rf_pred)
evaluate_model("XGBoost", y_test, xgb_pred)
evaluate_model("Naive Bayes", y_test, nb_pred)