# Prepara√ß√£o dos dados

<p align="justify">No contexto de projetos de an√°lise de dados e constru√ß√£o de modelos preditivos, a etapa de prepara√ß√£o dos dados assume um papel fundamental. O c√≥digo apresentado demonstra um fluxo de trabalho bem estruturado para o pr√©-processamento de um conjunto de dados possivelmente relacionado √† previs√£o de c√¢ncer colorretal. Cada etapa visa garantir que os modelos subsequentes recebam dados limpos, tratados e em um formato adequado para o aprendizado eficaz.</p>

## 1. Separa√ß√£o de features e targets:

<p align="justify">Nesta etapa incial √© feito a separa√ß√£o das colunas features (colunas gerais do dataset) e da coluna targets (coluna alvo a qual trat√° as respostas. </p>

```python
targets = ['Survival_Status']
# O restante dos dados em features (excluindo as colunas de targets) s√£o as vari√°veis explicativas ou inputs usadas como base para
# realizar as previs√µes.
features = df.drop(columns=targets)
```

## 2. Convers√£o e tratamento de valores num√©ricos e categ√≥ricos (Imputa√ß√£o):

<p align="justify"> Identifica√ß√£o de tipos de dados os quais foram separados em dois grupos, num√©ricos e categ√≥ricos. </p>

```python
# colunas com valores num√©ricos (ex.: idade, IMC).
numeric_features = features.select_dtypes(include=np.number).columns.tolist()
# colunas com valores categ√≥ricos/texto (ex.: g√™nero, ra√ßa, regi√£o).
categorical_features = features.select_dtypes(exclude=np.number).columns.tolist()
```

No c√≥digo, a classe `SimpleImputer` do `scikit-learn` √© utilizada com estrat√©gias diferentes para vari√°veis num√©ricas e categ√≥ricas:

* **Vari√°veis num√©ricas:** utiliza-se a **mediana**, uma medida robusta √† presen√ßa de outliers.
* **Vari√°veis categ√≥ricas:** aplica-se a **moda** (valor mais frequente), preservando a categoria mais representativa.

```python
# Criar pipelines de pr√©-processamentof
# Dados Num√©ricos
numeric_transformer = Pipeline(steps=[
     # Substitui valores faltantes pela mediana dos dados
    ('imputer', SimpleImputer(strategy='median')), # Trata valores ausentes em colunas num√©ricas
     # Converte os valores num√©ricos para uma escala comum (m√©dia 0 e desvio padr√£o 1) com o StandardScaler. Isso √© importante para
     # garantir que todas as vari√°veis num√©ricas sejam tratadas igualmente pelos modelos.
    ('scaler', StandardScaler())])

# Dados Categ√≥ricos
categorical_transformer = Pipeline(steps=[
    # Substitui valores faltantes com o valor mais frequente em cada categoria
    ('imputer', SimpleImputer(strategy='most_frequent')), # Trata valores ausentes em colunas categ√≥ricas
    # Converte valores de texto (categorias) em vari√°veis num√©ricas bin√°rias (0 ou 1) usando o OneHotEncoder. Isso permite que os
    # modelos entendam as informa√ß√µes categ√≥ricas. Em situa√ß√µes como codifica√ß√£o "One-Hot" (quando convertemos categorias em
    # vari√°veis bin√°rias), frequentemente temos matrizes esparsas,pois cada categoria corresponde a um √∫nico 1 em um vetor cheio de 0s.
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

# Criar o preprocessor usando ColumnTransformer. Combina√ß√£o dos Preprocessamentos. Isso organiza o preprocessamento de todas as colunas
# de forma eficiente. O ColumnTransformer aplica:
preprocessor = ColumnTransformer(
    transformers=[
        # O pipeline de dados num√©ricos (numeric_transformer) nas colunas definidas como numeric_features.
        ('num', numeric_transformer, numeric_features),
        # O pipeline de dados categ√≥ricos (categorical_transformer) nas colunas definidas como categorical_features.
        ('cat', categorical_transformer, categorical_features)])

# Ajustar e transformar os dados. Transforma√ß√£o e Cria√ß√£o de DataFrame. Aplica os pipelines (num√©ricos e categ√≥ricos) em todo
# o conjunto de dados features (colunas exceto as targets), retornando uma matriz contendo os dados pr√©-processados.
preprocessed_data = preprocessor.fit_transform(features)

# Extra√ß√£o dos Nomes das Vari√°veis.
# numeric_names: Mant√©m os nomes originais das colunas num√©ricas.
numeric_names = numeric_features
# categorical_names: Extrai os nomes das vari√°veis criadas pelo OneHotEncoder (ex.: Gender_Male, Gender_Female).
categorical_names = preprocessor.named_transformers_['cat'].named_steps['onehot']\
                   .get_feature_names_out(categorical_features)
# all_feature_names: Junta os nomes das colunas num√©ricas e categ√≥ricas em um √∫nico array.
all_feature_names = np.concatenate([numeric_names, categorical_names])

# Convers√£o para DataFrame para an√°lise (se sparse matrix). Os dados preprocessados s√£o convertidos em um DataFrame do pandas para
# facilitar a an√°lise. Se a matriz resultante for esparsa (√© uma estrutura na qual a maioria dos valores s√£o zeros. Ela √© utilizada
# para economizar mem√≥ria e tornar os c√°lculos mais eficientes.), ela ser√° convertida em um array denso (toarray() - armazena todos
# os valores explicitamente, incluindo os zeros. Este tipo de array n√£o otimiza mem√≥ria)
if hasattr(preprocessed_data, "toarray"):
    preprocessed_df = pd.DataFrame.sparse.from_spmatrix(preprocessed_data, columns=all_feature_names)
else:
    preprocessed_df = pd.DataFrame(preprocessed_data, columns=all_feature_names)

```
<p align="justify"> O tratamento de valores ausentes, como parte da limpeza de dados, est√° acontecendo dentro dos pipelines numeric_transformer e categorical_transformer, usando o SimpleImputer com diferentes estrat√©gias para colunas num√©ricas e categ√≥ricas. O ColumnTransformer aplica esses pipelines √†s colunas apropriadas, e o fit_transform executa a imputa√ß√£o durante a transforma√ß√£o dos dados. Esse tratamento evita a perda de dados relevantes e assegura que o conjunto final esteja completo e pronto para o treinamento dos modelos.</p>
<p align="justify">A presen√ßa de valores ausentes √© comum em bases de dados reais e pode comprometer significativamente o desempenho dos algoritmos de machine learning, j√° que a maioria deles n√£o lida diretamente com dados faltantes.</p>
<p align="justify"> Ap√≥s a imputa√ß√£o, os dados num√©ricos s√£o padronizados usando StandardScaler dentro do numeric_transformer. Essa etapa transforma os dados num√©ricos para que tenham m√©dia zero e desvio padr√£o um. Isso ajuda a evitar que vari√°veis com escalas diferentes dominem o modelo e melhora o desempenho de alguns algoritmos.</p>
<p align="justify">As vari√°veis categ√≥ricas s√£o transformadas usando OneHotEncoder dentro do categorical_transformer. Essa etapa converte cada categoria em uma nova coluna bin√°ria (0/1), evitando que o modelo interprete as categorias como tendo uma ordem intr√≠nseca.</p>
<p align="justify">O ColumnTransformer combina os pipelines numeric_transformer e categorical_transformer e os aplica √†s colunas apropriadas (numeric_features e categorical_features, respectivamente).</p>
<p align="justify">A fun√ß√£o fit_transform ajusta os pipelines aos dados de entrada (features) e, em seguida, transforma os dados aplicando todas as etapas de transforma√ß√£o definidas nos pipelines.</p>
<p align="justify">A transforma√ß√£o de dados envolve imputa√ß√£o de valores ausentes, padroniza√ß√£o de dados num√©ricos, codifica√ß√£o one-hot para dados categ√≥ricos e a aplica√ß√£o dessas transforma√ß√µes usando pipelines e ColumnTransformer. Essas etapas s√£o essenciais para preparar os dados do Datasete C√¢ncer Colorretal, garantindo que ele possa lidar com valores ausentes, diferentes escalas de vari√°veis e dados categ√≥ricos de forma eficaz.</p>

# Descri√ß√£o dos modelos

## Randon Forest:

<p align="justify">O Randon Forest √© um algoritmo de ensemble baseado em √°rvores de decis√£o. Quando se combina v√°rias √°rvores, temos uma floresta. Ele cria v√°rias √°rvores de decis√£o usando conjuntos de dados aleat√≥rios e, em seguida, combina as previs√µes de cada √°rvore para produzir uma previs√£o final. O Random Forest √© um conjunto de v√°rias √°rvores de decis√£o que trabalham juntas para fazer previs√µes mais precisas. Ao inv√©s de depender de uma √∫nica √°rvore, ele cria m√∫ltiplas √°rvores e combina suas respostas. Isso o torna mais robusto e menos propenso a erros causados por varia√ß√µes nos dados. Ele usa a vota√ß√£o entre √°rvores para prever categorias e a m√©dia das previs√µes para problemas de regress√£o.</p>
<p align="justify">Como funciona?</p>
<p align="justify"><strong>Cria√ß√£o de v√°rias √°rvores de decis√£o ‚Üí</strong> O algoritmo constr√≥i v√°rias √°rvores, cada uma com um conjunto ligeiramente diferente de dados.</p>
<p align="justify"><strong>Cada √°rvore faz uma previs√£o ‚Üí</strong> Quando recebe um novo dado, cada √°rvore d√° um "palpite" sobre a classe correta.</p>
<p align="justify"><strong>Vota√ß√£o das √°rvores (Classifica√ß√£o) ‚Üí</strong> No caso de classifica√ß√£o, cada √°rvore vota e a resposta mais escolhida entre todas √© a decis√£o final.</p>
<p align="justify"><strong>M√©dia das previs√µes (Regress√£o) ‚Üí</strong> Para problemas de regress√£o, o resultado final √© uma m√©dia das previs√µes feitas pelas √°rvores.</p>

<p align="justify">Descri√ß√£o do c√≥digo:</p>

```python
# Separa√ß√£o entre features (X) e target (y)
# Separa√ß√£o de Dados: Os dados s√£o divididos entre X (features) e y (target, no caso a sobreviv√™ncia).
# Dados tratados
# Define X como os dados que foram pr√©-processados no c√≥digo acima apresentado na √°rea de tratamento de dados.
X = preprocessed_df
# Convers√£o da Target: Transformamos "Survived" em 1 e "Deceased" em 0.
# Converte a vari√°vel alvo ("Survived" ‚Üí 1 e "Deceased" ‚Üí 0) para valores num√©ricos.
y = df['Survival_Status'].replace({'Survived': 1, 'Deceased': 0}).infer_objects(copy=False)

```

```python
# Divis√£o do Dataset: O dataset √© dividido em treinamento (80%) e teste (20%) para avaliar o desempenho dos modelos. (Obs. Testamos tamb√©m com outras porcentagens que ser√£o descritas abaixo.)
# Treinamento dos Modelos: Cada modelo recebe os dados de treinamento (X_train, y_train) e aprende padr√µes para fazer previs√µes.
# Divide os dados em: 80% treino ‚Üí usados para ensinar os modelos. 20% teste ‚Üí usados para validar os modelos.
# Garante que a divis√£o seja reprodut√≠vel (os mesmos conjuntos sempre que o c√≥digo for executado).
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print para informa√ß√£o de quantidade de linhas e colunas sendo usadas em X_train e X_test.
print(f"N√∫mero de linhas em X_train: {X_train.shape[0]}")
print(f"N√∫mero de colunas em X_train: {X_train.shape[1]}")

print(f"N√∫mero de linhas em X_test: {X_test.shape[0]}")
print(f"N√∫mero de colunas em X_test: {X_test.shape[1]}")

```

```python
# 1Ô∏è‚É£ Modelo Random Forest
# Cria um modelo Random Forest com 100 √°rvores. (Obs. Testamos tamb√©m com outras quantidades de √°rvores que ser√£o descritas abaixo.)

# O Random Forest √© um algoritmo baseado em m√∫ltiplas √°rvores de decis√£o. Cada √°rvore aprende um pequeno aspecto dos dados e, no final, todas as √°rvores juntas fazem uma vota√ß√£o para dar uma previs√£o mais robusta.
# üîπ Mais √°rvores = mais estabilidade. Quando o modelo tem poucas √°rvores, ele pode ter mais varia√ß√µes e ser sens√≠vel a mudan√ßas nos dados. Com mais √°rvores, ele generaliza melhor, reduzindo o risco de tomar decis√µes erradas devido a dados espec√≠ficos do treino.

# üîπ Aprimora a precis√£o Geralmente, aumentar o n√∫mero de √°rvores melhora a precis√£o, pois cada √°rvore traz uma perspectiva diferente sobre os dados.

# üîπ Compromisso entre desempenho e tempo de execu√ß√£o Testes pr√°ticos mostram que 100 √°rvores √© um bom n√∫mero para equilibrar qualidade e velocidade.

# Se tivermos milhares de √°rvores, o treinamento pode ficar muito lento sem ganhos significativos na precis√£o.
# O Bagging ocorre quando est√° sendo instanciado um modelo RandomForestClassifier com n_estimators=100, ou seja, 100 √°rvores de decis√£o ser√£o treinadas usando subconjuntos aleat√≥rios do seu dataset.
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Treina o modelo nos dados de treino.
# O Random Forest tamb√©m aplica Feature Selection automaticamente ao treinar o modelo (rf_model.fit(X_train, y_train)).
# Ele seleciona aleatoriamente um subconjunto de atributos para cada √°rvore, reduzindo a depend√™ncia de atributos irrelevantes
rf_model.fit(X_train, y_train)

# Obter import√¢ncia das features (Feature Selection)
feature_importances = rf_model.feature_importances_

# Ordenar e visualizar
indices = np.argsort(feature_importances)[::-1]  # Ordena do maior para o menor
plt.figure(figsize=(30, 20))
plt.title("Import√¢ncia das Features no Random Forest")
plt.barh(range(X_train.shape[1]), feature_importances[indices])
plt.yticks(range(X_train.shape[1]), np.array(all_feature_names)[indices])
plt.gca().invert_yaxis()  # Opcional: coloca a feature mais importante no topo
plt.xlabel("Import√¢ncia")
plt.ylabel("Features")
plt.show()

# Faz previs√µes no conjunto de teste.
rf_pred = rf_model.predict(X_test)

```

```python

# Matriz de Confus√£o para Random Forest
# Ela compara os valores reais (y_test) com os valores preditos (rf_pred) pelo modelo Random Forest.
cm_rf = confusion_matrix(y_test, rf_pred)
# Cria uma nova √°rea de figura do matplotlib, definindo o tamanho dela: 8 de largura por 6 de altura.
plt.figure(figsize=(8, 6))
# sns.heatmap √© a fun√ß√£o do Seaborn que desenha uma mapa de calor (heatmap).
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Deceased', 'Survived'], yticklabels=['Deceased', 'Survived'])
# Define o t√≠tulo do eixo X como "Valores Previstos".
plt.xlabel('Valores Previstos')
# Define o t√≠tulo do eixo Y como "Valores Reais".
plt.ylabel('Valores Reais')
# Define o t√≠tulo do gr√°fico.
plt.title('Matriz de Confus√£o: Random Forest')
# Exibe o gr√°fico na tela.
plt.show()

```

<p align="justify">Comparando com outros modelos XGBoost e Naive Bayes</p>

```python

# 2Ô∏è‚É£ Modelo XGBoost
# Cria um modelo XGBoost.
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
# Treina o modelo com os dados de treino.
xgb_model.fit(X_train, y_train)
xgb_importances = xgb_model.feature_importances_
indices = np.argsort(xgb_importances)[::-1]

plt.figure(figsize=(30, 20))
plt.title("Import√¢ncia das Features no XGBoost")
plt.barh(range(X_train.shape[1]), xgb_importances[indices])
plt.yticks(range(X_train.shape[1]), np.array(all_feature_names)[indices])
plt.gca().invert_yaxis()
plt.xlabel("Import√¢ncia")
plt.ylabel("Features")
plt.show()
# Faz previs√µes no conjunto de teste.
xgb_pred = xgb_model.predict(X_test)

# Matriz de Confus√£o para XGBoost
cm_xgb = confusion_matrix(y_test, xgb_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Deceased', 'Survived'], yticklabels=['Deceased', 'Survived'])
plt.xlabel('Valores Previstos')
plt.ylabel('Valores Reais')
plt.title('Matriz de Confus√£o: XGBoost')
plt.show()

```

```python

# 3Ô∏è‚É£ Modelo Naive Bayes
# Cria um modelo Naive Bayes baseado na distribui√ß√£o normal.
nb_model = GaussianNB()
# Treina o modelo com os dados de treino.
nb_model.fit(X_train, y_train)
# Obtemos as m√©dias das features para cada classe
means = nb_model.theta_  # shape: (n_classes, n_features)

# Calculamos a diferen√ßa absoluta entre as m√©dias das classes
# Para problemas bin√°rios, podemos fazer isso assim:
mean_diff = np.abs(means[1] - means[0])

# Ordena as features pela diferen√ßa
indices = np.argsort(mean_diff)[::-1]

# Plota as diferen√ßas como "import√¢ncias"
plt.figure(figsize=(30, 20))
plt.title("Diferen√ßa entre m√©dias das classes (interpreta√ß√£o de import√¢ncia) - Naive Bayes")
plt.barh(range(X_train.shape[1]), mean_diff[indices])
plt.yticks(range(X_train.shape[1]), np.array(all_feature_names)[indices])
plt.gca().invert_yaxis()
plt.xlabel("Diferen√ßa entre m√©dias")
plt.ylabel("Features")
plt.show()
# Faz previs√µes no conjunto de teste.
nb_pred = nb_model.predict(X_test)

# Matriz de Confus√£o para Naive Bayes
cm_nb = confusion_matrix(y_test, nb_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Oranges',
            xticklabels=['Deceased', 'Survived'], yticklabels=['Deceased', 'Survived'])
plt.xlabel('Valores Previstos')
plt.ylabel('Valores Reais')
plt.title('Matriz de Confus√£o: Naive Bayes')
plt.show()

```

<p align="justify">Calculando, exibindo as m√©tricas e avaliando os tr√™s modelos.</p>

```python

# Fun√ß√£o para calcular e exibir as m√©tricas
# Avalia√ß√£o dos Modelos: O c√≥digo mede o desempenho dos tr√™s modelos usando as m√©tricas: üîπ Acur√°cia (quantidade de previs√µes corretas) üîπ Precis√£o (qu√£o correto √© quando prev√™ sobreviv√™ncia)
# üîπ Recall (quantos casos de sobreviv√™ncia foram corretamente identificados) üîπ F1-score (m√©dia harm√¥nica entre precis√£o e recall)
# Define uma fun√ß√£o evaluate_model(name, y_test, y_pred), que recebe: name ‚Üí Nome do modelo. // y_test ‚Üí Verdadeiro status de sobreviv√™ncia. // y_pred ‚Üí Previs√µes do modelo.
# Calcula e exibe as m√©tricas de desempenho: Acur√°cia ‚Üí Percentagem de previs√µes corretas. // Precis√£o ‚Üí Qu√£o correto √© quando prev√™ sobreviv√™ncia. // Recall ‚Üí Quantos casos de sobreviv√™ncia foram identificados corretamente.
# F1-score ‚Üí Combina√ß√£o entre precis√£o e recall.
def evaluate_model(name, y_test, y_pred):
    print(f"\nResultados para {name}:")
    print(f"Acur√°cia: {accuracy_score(y_test, y_pred):.4f}")
    print(f"Precis√£o: {precision_score(y_test, y_pred):.4f}")
    print(f"Recall: {recall_score(y_test, y_pred):.4f}")
    print(f"F1-Score: {f1_score(y_test, y_pred):.4f}")

# Avalia√ß√£o dos modelos
# Chama a fun√ß√£o evaluate_model para cada modelo, imprimindo os resultados das m√©tricas.
evaluate_model("Random Forest", y_test, rf_pred)
evaluate_model("XGBoost", y_test, xgb_pred)
evaluate_model("Naive Bayes", y_test, nb_pred)

```

<p align="justify">Apura√ß√£o:</p>

<p align="justify">O print abaixo apresenta a avalia√ß√£o de desempenho dos tr√™s modelos de classifica√ß√£o ‚Äî Random Forest, XGBoost e Naive Bayes ‚Äî utilizando tr√™s divis√µes distintas dos dados: 90% treino e 10% teste, 80% treino e 20% teste, e 70% treino e 30% teste. Para cada configura√ß√£o, foram testados diferentes n√∫meros de √°rvores (100, 200, 300 e 400 √°rvores) nos modelos Random Forest e XGBoost. As m√©tricas calculadas foram Acur√°cia (percentual de previs√µes corretas no total), Precis√£o (qu√£o correto o modelo foi ao prever a sobreviv√™ncia), Recall (quantidade de casos de sobreviv√™ncia corretamente identificados) e F1-Score (harmoniza√ß√£o entre Precis√£o e Recall). De modo geral, os valores de Acur√°cia e F1-Score mantiveram-se bastante elevados para todos os modelos, com destaque para o Naive Bayes, que apresentou recall de 100% em todas as divis√µes dos dados, enquanto Random Forest e XGBoost tiveram uma leve queda de desempenho conforme a propor√ß√£o de teste aumentava.</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/4a5d2aad-c333-4cf8-a102-3ad7e0d93ef2" alt="image">
</p>

<p align="justify">J√° o print abaixo apresenta a an√°lise detalhada dos resultados em termos absolutos: quantidade de Verdadeiros Negativos (casos corretamente classificados como n√£o sobreviventes), Falsos Positivos (casos incorretamente classificados como sobreviventes), Falsos Negativos (casos incorretamente classificados como n√£o sobreviventes) e Verdadeiros Positivos (casos corretamente classificados como sobreviventes). Em todas as divis√µes e para todos os modelos, o n√∫mero de Falsos Negativos √© extremamente baixo ou mesmo zero, indicando alta capacidade dos modelos em identificar corretamente os casos de sobreviv√™ncia. O Naive Bayes apresentou resultados perfeitos (zero falsos negativos e falsos positivos) em todas as situa√ß√µes testadas, refor√ßando sua alta sensibilidade (recall) e especificidade. Em compara√ß√£o, os modelos Random Forest e XGBoost, apesar de tamb√©m apresentarem excelentes resultados, tiveram uma pequena quantidade de erros, sobretudo no aumento da propor√ß√£o de teste.</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/3e135ecc-49fd-4f97-b103-1f64f1183209" alt="image">
</p>

<p align="justify">Resultado:</p>

<p align="justify">Ap√≥s apura√ß√£o, chegamos ao veredito em que o cen√°rio que apresentou o melhor desempenho foi com treinamento de 80% e teste de 20% com 100 √°rvores de decis√£o. Com isso, apresentamos abaixo os prints das matrizes de confus√£o deste cen√°rio em espec√≠fico:</p>

<p align="justify">Matriz de confus√£o Randon Forest:</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/d313818c-0eda-474f-b97b-2d5e64b28c92" alt="image">
</p>

<p align="justify">Matriz de confus√£o XGBoost:</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/64b49233-4fbd-4d19-8cb8-a1e78ef0feff" alt="image">
</p>

<p align="justify">Matriz de confus√£o Naive Bayes:</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/632ebad6-7b43-4d27-ac01-5379bd8dee95" alt="image">
</p>

<p align="justify">Analisando os resultados gerais, os tr√™s modelos obtiveram desempenhos muito bons, com pequenas varia√ß√µes entre eles conforme o volume de dados de teste aumentava. O Random Forest e o XGBoost apresentaram uma pequena perda de desempenho em termos de precis√£o e F1-Score √† medida que a porcentagem de teste aumentava. J√° o Naive Bayes se destacou pela consist√™ncia: manteve precis√£o, recall e F1-Score elevados (pr√≥ximos de 1.0) em todas as divis√µes de treino/teste, sem apresentar erros (falsos positivos ou falsos negativos) nos dados de valida√ß√£o. Com base nos resultados apresentados, o Naive Bayes foi o m√©todo que apresentou o melhor desempenho geral, demonstrando tanto alta capacidade de identifica√ß√£o dos sobreviventes quanto estabilidade nas diferentes propor√ß√µes de divis√£o dos dados.</p>


## XGBoost:

<p align="justify">O XGBoost √© um algoritmo de aprendizado de m√°quina de ensemble baseado na t√©cnica de gradient boosting. Ele constr√≥i um modelo preditivo forte combinando sequencialmente m√∫ltiplos modelos fracos (tipicamente √°rvores de decis√£o), onde cada novo modelo tenta corrigir os erros dos modelos anteriores.</p>

O XGBoost se destaca por suas otimiza√ß√µes que o tornam altamente eficiente e preciso, incluindo:

* Regulariza√ß√£o para evitar overfitting.
* Tratamento nativo de valores ausentes.
* Processamento paralelo para treinamento mais r√°pido.
* Otimiza√ß√µes na constru√ß√£o das √°rvores.
* Flexibilidade com fun√ß√µes de perda personalizadas.
* Taxa de aprendizado ("shrinkage") para maior robustez.

#### 1 Descri√ß√£o do C√≥digo:
```python
# Crie a matriz de features (X)
  X = df_processed[feature_columns]
  # Cria um novo DataFrame chamado 'X' contendo apenas as colunas listadas em 'feature_columns' do DataFrame 'df_processed'.
  # 'X' representa a matriz de features que ser√° utilizada para treinar os modelos de machine learning.

  # Crie as vari√°veis dependentes (y) para cada alvo
  y_survival = df_processed['Survival_Status_Survived'] # Assumindo que 'Survived' √© o positivo
  # Cria uma Series chamada 'y_survival' contendo os valores da coluna 'Survival_Status_Survived' do DataFrame 'df_processed'.
  # Esta Series representa a vari√°vel dependente (o alvo) para a tarefa de prever a sobreviv√™ncia.
  # Assume-se que o valor 1.0 nesta coluna indica que o paciente sobreviveu (o r√≥tulo positivo).

  y_chemo = df_processed['Chemotherapy_Received_Yes'] # Assumindo que 'Yes' √© o positivo
  # Cria uma Series chamada 'y_chemo' contendo os valores da coluna 'Chemotherapy_Received_Yes' do DataFrame 'df_processed'.
  # Esta Series representa a vari√°vel dependente para a tarefa de prever se o paciente recebeu quimioterapia.
  # Assume-se que o valor 1.0 nesta coluna indica que o paciente recebeu quimioterapia (o r√≥tulo positivo).

  y_radio = df_processed['Radiotherapy_Received_Yes'] # Assumindo que 'Yes' √© o positivo
  # Cria uma Series chamada 'y_radio' contendo os valores da coluna 'Radiotherapy_Received_Yes' do DataFrame 'df_processed'.
  # Esta Series representa a vari√°vel dependente para a tarefa de prever se o paciente recebeu radioterapia.
  # Assume-se que o valor 1.0 nesta coluna indica que o paciente recebeu radioterapia (o r√≥tulo positivo).

  y_surgery = df_processed['Surgery_Received_Yes'] # Assumindo que 'Yes' √© o positivo
  # Cria uma Series chamada 'y_surgery' contendo os valores da coluna 'Surgery_Received_Yes' do DataFrame 'df_processed'.
  # Esta Series representa a vari√°vel dependente para a tarefa de prever se o paciente passou por cirurgia.
  # Assume-se que o valor 1.0 nesta coluna indica que o paciente passou por cirurgia (o r√≥tulo positivo).
```

#### 2 Divis√£o de Dados em Treinamento e Teste para Modelagem de Sobreviv√™ncia ao C√¢ncer de Colorretal:

```python
from sklearn.model_selection import train_test_split
# Importa a fun√ß√£o 'train_test_split' da biblioteca 'sklearn.model_selection'.
# Esta fun√ß√£o √© essencial para dividir um conjunto de dados em subconjuntos separados
# para treinamento de um modelo de machine learning e para avaliar seu desempenho em dados n√£o vistos.

# Exemplo para o alvo 'Survival_Status'
# Coment√°rio indicando que o c√≥digo a seguir realiza a divis√£o dos dados
# especificamente para a vari√°vel alvo 'Survival_Status'.

X_train_survival, X_test_survival, y_train_survival, y_test_survival = train_test_split(
    X, y_survival, test_size=0.2, random_state=42
)
# Chama a fun√ß√£o 'train_test_split' para dividir os dados em conjuntos de treinamento e teste.
# - 'X': Representa a matriz de features (vari√°veis independentes) que ser√£o usadas para a previs√£o.
# - 'y_survival': Representa a vari√°vel alvo (dependente) que queremos prever, neste caso, a sobreviv√™ncia.
# - 'test_size=0.2': Especifica que 20% do conjunto de dados original ser√° reservado para o conjunto de teste.
#                    Os 80% restantes ser√£o usados para o conjunto de treinamento.
# - 'random_state=42': Define uma semente para o gerador de n√∫meros aleat√≥rios.
#                      Isso garante que a divis√£o dos dados seja a mesma cada vez que o c√≥digo for executado,
#                      o que √© importante para a reprodutibilidade dos resultados.
# A fun√ß√£o retorna quatro conjuntos de dados:
# - 'X_train_survival': As features para o conjunto de treinamento do modelo de sobreviv√™ncia.
# - 'X_test_survival': As features para o conjunto de teste do modelo de sobreviv√™ncia.
# - 'y_train_survival': A vari√°vel alvo (sobreviv√™ncia) para o conjunto de treinamento.
# - 'y_test_survival': A vari√°vel alvo (sobreviv√™ncia) para o conjunto de teste.
```

#### 3 Importa√ß√£o do Classificador XGBoost para Modelagem Preditiva:
```python
rom xgboost import XGBClassifier
# Importa a classe 'XGBClassifier' da biblioteca 'xgboost'.
# O 'XGBClassifier' √© uma implementa√ß√£o do algoritmo de Gradient Boosting
# para problemas de classifica√ß√£o. √â um modelo poderoso e frequentemente
# utilizado em tarefas de machine learning devido ao seu desempenho e
# capacidade de lidar com dados complexos. Ao importar esta classe,
# tornamos dispon√≠vel o uso do algoritmo XGBoost para construir
# modelos de classifica√ß√£o em nossos dados.
```

#### 4 Inicializa√ß√£o de Modelos XGBoost com Par√¢metros Padr√£o e Ajustados:
```python
# Usando par√¢metros padr√£o
model = XGBClassifier()
# Cria uma inst√¢ncia do classificador XGBoost (XGBClassifier) com seus par√¢metros default.
# Ao n√£o especificar nenhum par√¢metro, o modelo utilizar√° as configura√ß√µes padr√£o definidas na biblioteca xgboost.
# Esta √© uma maneira r√°pida de criar um modelo base para come√ßar a experimentar ou para comparar com modelos ajustados.
# A inst√¢ncia do modelo √© armazenada na vari√°vel 'model'.

# Especificando hiperpar√¢metros (exemplo)
model_tuned = XGBClassifier(objective='binary:logistic', # Especifica o objetivo da tarefa de classifica√ß√£o como log√≠stica bin√°ria.
                                                    # Isso √© adequado para problemas onde a vari√°vel alvo tem duas classes (0 ou 1).
                            n_estimators=100,          # Define o n√∫mero de √°rvores de boosting (ou "estimators") que ser√£o constru√≠das no modelo.
                                                    # Mais √°rvores podem levar a um melhor desempenho, mas tamb√©m a um maior tempo de treinamento e risco de overfitting.
                            learning_rate=0.1,         # Controla a taxa de aprendizado, que determina o passo de encolhimento usado para evitar o overfitting.
                                                    # Valores menores tornam o aprendizado mais lento, mas podem levar a um modelo mais robusto.
                            max_depth=3,               # Define a profundidade m√°xima de cada √°rvore individual.
                                                    # Controla a complexidade do modelo; √°rvores mais profundas podem capturar rela√ß√µes mais complexas, mas tamb√©m podem overfit.
                            random_state=42)
# Cria outra inst√¢ncia do classificador XGBoost (XGBClassifier), mas desta vez especificando manualmente alguns hiperpar√¢metros.
# Os hiperpar√¢metros s√£o configura√ß√µes que n√£o s√£o aprendidas diretamente pelos dados, mas que s√£o definidas antes do treinamento.
# Ajustar esses par√¢metros ('tuning') √© uma etapa importante para otimizar o desempenho do modelo para um problema espec√≠fico.
# 'random_state=42' garante que a inicializa√ß√£o aleat√≥ria do modelo seja a mesma cada vez que o c√≥digo √© executado, para reprodutibilidade.
# A inst√¢ncia do modelo com hiperpar√¢metros ajustados √© armazenada na vari√°vel 'model_tuned'.
```

#### 5 Treinamento do Modelo XGBoost Ajustado com Dados de Sobreviv√™ncia:
```python
# Use os dados de treinamento para ajustar o modelo com hiperpar√¢metros
model_tuned.fit(X_train_survival, y_train_survival)
# Chama o m√©todo 'fit()' da inst√¢ncia do modelo XGBoost que foi inicializada com hiperpar√¢metros ('model_tuned').
# O m√©todo 'fit()' √© respons√°vel por treinar o modelo usando os dados fornecidos.
# - 'X_train_survival': Cont√©m as features (vari√°veis independentes) do conjunto de treinamento.
#                      O modelo aprender√° os padr√µes nesses dados para fazer previs√µes.
# - 'y_train_survival': Cont√©m a vari√°vel alvo (dependente) correspondente ao conjunto de treinamento.
#                      Neste caso, representa a informa√ß√£o de sobreviv√™ncia para cada amostra no conjunto de treinamento.
# Durante o treinamento, o algoritmo XGBoost itera sobre as √°rvores de boosting,
# ajustando seus par√¢metros internos para minimizar o erro entre as previs√µes do modelo
# e os valores reais da vari√°vel alvo no conjunto de treinamento.
# Ap√≥s a execu√ß√£o desta linha, o modelo 'model_tuned' estar√° treinado e pronto para ser usado
# para fazer previs√µes em novos dados (como o conjunto de teste).
```

#### 6 Realiza√ß√£o de Previs√µes de Sobreviv√™ncia com o Modelo XGBoost Treinado:

```python
y_pred_survival = model.predict(X_test_survival)
# Utiliza o m√©todo 'predict()' do modelo XGBoost treinado ('model') para gerar previs√µes
# sobre o conjunto de dados de teste ('X_test_survival').
# O modelo, tendo sido previamente treinado com os dados de treinamento, agora aplica o conhecimento
# aprendido para prever a classe (neste caso, se o paciente sobreviveu ou n√£o) para cada amostra
# presente no conjunto de teste.
# As previs√µes geradas pelo modelo s√£o armazenadas na vari√°vel 'y_pred_survival' como um array NumPy.
# Cada elemento deste array representa a classe prevista para a amostra correspondente em 'X_test_survival'.

print(y_pred_survival)
# Imprime o conte√∫do da vari√°vel 'y_pred_survival', que cont√©m as previs√µes de classe
# (provavelmente representadas por 0 e 1) para cada paciente no conjunto de teste.
# Esta sa√≠da permite visualizar as previs√µes feitas pelo modelo e compar√°-las posteriormente
# com os valores reais da vari√°vel alvo no conjunto de teste ('y_test_survival') para avaliar o desempenho do modelo.
```
#### 7. Importa√ß√£o de M√©tricas de Avalia√ß√£o do scikit-learn:
```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# Importa fun√ß√µes espec√≠ficas do m√≥dulo 'metrics' da biblioteca 'sklearn' (scikit-learn).
# Estas fun√ß√µes s√£o utilizadas para avaliar o desempenho de modelos de classifica√ß√£o,
# comparando as previs√µes feitas pelo modelo com os valores reais da vari√°vel alvo no conjunto de teste.
# - 'accuracy_score': Calcula a acur√°cia do modelo, que √© a propor√ß√£o de previs√µes corretas
#                   em rela√ß√£o ao n√∫mero total de previs√µes.
# - 'confusion_matrix': Gera uma matriz de confus√£o, que √© uma tabela que descreve o desempenho
#                     de um classificador em rela√ß√£o aos r√≥tulos verdadeiros. Ela mostra
#                     os verdadeiros positivos, verdadeiros negativos, falsos positivos e falsos negativos.
# - 'classification_report': Produz um relat√≥rio de texto que fornece m√©tricas de precis√£o,
#                          recall, F1-score e suporte para cada classe do problema de classifica√ß√£o.
#                          √â uma maneira abrangente de avaliar o desempenho do modelo por classe.
# Ao importar essas fun√ß√µes, tornamos dispon√≠vel o uso dessas m√©tricas para analisar a qualidade
# das previs√µes feitas pelo nosso modelo XGBoost.
```

#### 8. Avalia√ß√£o da Acur√°cia do Modelo de Sobreviv√™ncia:
```python
from sklearn.metrics import accuracy_score
# Importa a fun√ß√£o 'accuracy_score' do m√≥dulo 'metrics' da biblioteca 'sklearn'.
# Esta fun√ß√£o calcula a acur√°cia, que representa a propor√ß√£o de previs√µes corretas
# feitas pelo modelo em rela√ß√£o ao n√∫mero total de amostras no conjunto de teste.

accuracy = accuracy_score(y_test_survival, y_pred_survival)
# Chama a fun√ß√£o 'accuracy_score' para calcular a acur√°cia do modelo.
# - 'y_test_survival': Cont√©m os r√≥tulos verdadeiros (os valores reais da vari√°vel alvo 'Survival_Status')
#                    para as amostras no conjunto de teste.
# - 'y_pred_survival': Cont√©m as previs√µes de classe (0 ou 1 para n√£o sobreviv√™ncia ou sobreviv√™ncia)
#                    feitas pelo modelo para as mesmas amostras no conjunto de teste.
# O resultado da fun√ß√£o, que √© o valor da acur√°cia, √© armazenado na vari√°vel 'accuracy'.

print(f"Acur√°cia do modelo: {accuracy}")
# Imprime o valor da acur√°cia do modelo formatado em uma string.
# Esta sa√≠da informa a porcentagem de vezes que o modelo fez a previs√£o correta sobre a sobreviv√™ncia dos pacientes no conjunto de teste.
# A acur√°cia √© uma m√©trica geral de desempenho, mas sua interpreta√ß√£o pode depender do balanceamento das classes no conjunto de dados.
```
Resulado: Acur√°cia do modelo: 0.7468452943465451
#### 9. Gera√ß√£o do Relat√≥rio de Classifica√ß√£o para Avalia√ß√£o Detalhada do Modelo de Sobreviv√™ncia:

```python
from sklearn.metrics import classification_report
# Importa a fun√ß√£o 'classification_report' do m√≥dulo 'metrics' da biblioteca 'sklearn'.
# Esta fun√ß√£o gera um relat√≥rio de texto que fornece m√©tricas de avalia√ß√£o detalhadas
# para cada classe do problema de classifica√ß√£o. As m√©tricas incluem precis√£o, recall,
# F1-score e suporte (o n√∫mero de ocorr√™ncias reais de cada classe).

report = classification_report(y_test_survival, y_pred_survival)
# Chama a fun√ß√£o 'classification_report' para gerar o relat√≥rio.
# - 'y_test_survival': Cont√©m os r√≥tulos verdadeiros (os valores reais da vari√°vel alvo)
#                    para as amostras no conjunto de teste.
# - 'y_pred_survival': Cont√©m as previs√µes de classe feitas pelo modelo para as mesmas amostras.
# A fun√ß√£o compara os r√≥tulos verdadeiros com as previs√µes e calcula as m√©tricas de desempenho para cada classe.
# O relat√≥rio gerado √© armazenado na vari√°vel 'report' como uma string.

print("Relat√≥rio de Classifica√ß√£o:")
# Imprime um cabe√ßalho indicando que a sa√≠da a seguir √© o relat√≥rio de classifica√ß√£o.

print(report)
# Imprime o relat√≥rio de classifica√ß√£o. Este relat√≥rio fornece uma vis√£o detalhada
# do desempenho do modelo para cada classe individualmente, incluindo:
# - Precis√£o: Das amostras que o modelo classificou como pertencentes a uma classe,
#             qual propor√ß√£o realmente pertence a essa classe.
# - Recall: De todas as amostras que realmente pertencem a uma classe,
#           qual propor√ß√£o o modelo conseguiu classificar corretamente.
# - F1-score: A m√©dia harm√¥nica ponderada da precis√£o e do recall.
# - Support: O n√∫mero de amostras reais de cada classe no conjunto de teste.
# Al√©m das m√©tricas por classe, o relat√≥rio tamb√©m inclui m√©dias ponderadas e macro dessas m√©tricas.

Relat√≥rio de Classifica√ß√£o:
              precision    recall  f1-score   support

         0.0       0.25      0.01      0.02      4471
         1.0       0.75      0.99      0.85     13518

    accuracy                           0.75     17989
   macro avg       0.50      0.50      0.44     17989
weighted avg       0.63      0.75      0.65     17989
```
#### 10. Visualiza√ß√£o da Matriz de Confus√£o com Yellowbrick para Avalia√ß√£o do Modelo de Sobreviv√™ncia:
```python
from yellowbrick.classifier import ConfusionMatrix
# Importa a classe 'ConfusionMatrix' do m√≥dulo 'classifier' da biblioteca 'yellowbrick'.
# Esta classe fornece uma representa√ß√£o visual da matriz de confus√£o, facilitando a an√°lise
# do desempenho de um classificador ao exibir as contagens de verdadeiros positivos,
# verdadeiros negativos, falsos positivos e falsos negativos.

import matplotlib.pyplot as plt
# Importa o m√≥dulo 'pyplot' da biblioteca 'matplotlib', essencial para exibir gr√°ficos e visualiza√ß√µes
# geradas por outras bibliotecas, como o Yellowbrick.

# Supondo que 'model' seja sua inst√¢ncia treinada do XGBClassifier
# Este coment√°rio assume que voc√™ j√° treinou um modelo XGBoost e o armazenou na vari√°vel 'model'.
cm = ConfusionMatrix(model, classes=['N√£o Sobreviveu', 'Sobreviveu']) # Adapte os nomes das classes se necess√°rio
# Cria uma inst√¢ncia do visualizador 'ConfusionMatrix' do Yellowbrick.
# - 'model': O classificador XGBoost previamente treinado que ser√° avaliado.
# - 'classes': Uma lista opcional contendo os nomes das classes alvo. Isso melhora a legibilidade
#              do gr√°fico, rotulando os eixos corretamente. Certifique-se de que a ordem corresponde
#              √† ordem das classes nos seus dados alvo (por exemplo, 0 e 1).

# Ajuste o visualizador aos dados de treinamento
# Este coment√°rio indica a etapa de "ajuste" do visualizador aos dados de treinamento.
cm.fit(X_train_survival, y_train_survival)
# O m√©todo 'fit()' do visualizador 'ConfusionMatrix' recebe os dados de treinamento.
# Embora a matriz de confus√£o seja avaliada nos dados de teste, o visualizador pode usar
# as informa√ß√µes dos dados de treinamento (como as classes presentes) para configurar a visualiza√ß√£o.

# Avalie o modelo nos dados de teste usando o visualizador e exiba a matriz de confus√£o
# Este coment√°rio descreve a etapa de avalia√ß√£o do modelo nos dados de teste e a exibi√ß√£o da matriz.
cm.score(X_test_survival, y_test_survival)
# O m√©todo 'score()' do visualizador 'ConfusionMatrix' recebe os dados de teste e os r√≥tulos verdadeiros.
# Ele usa o modelo treinado para fazer previs√µes nos dados de teste e ent√£o compara essas
# previs√µes com os r√≥tulos verdadeiros para calcular e exibir a matriz de confus√£o visualmente.

cm.show() # Ou plt.show()
# Exibe a visualiza√ß√£o da matriz de confus√£o gerada pelo Yellowbrick.
# 'cm.show()' √© um m√©todo espec√≠fico do Yellowbrick para mostrar a figura.
# Alternativamente, 'plt.show()' do matplotlib tamb√©m pode ser usado para exibir a figura.
```
![Matriz de confus√£o](https://github.com/ICEI-PUC-Minas-PMV-SI/PMV-SI-2025-1-PE7-T1-Cancer-Colorretal/blob/main/docs/img/Matriz%20de%20confusao.png)

##### Vi√©s do Modelo na Previs√£o de Sobreviv√™ncia: An√°lise da Matriz de Confus√£o e o Impacto dos Falsos Positivos

* Verdadeiros Negativos (TN): 41

O modelo previu que 41 pacientes n√£o sobreviveram, e eles realmente n√£o sobreviveram.

* Falsos Positivos (FP): 4430

O modelo previu que 4430 pacientes sobreviveram, mas na verdade n√£o sobreviveram. Este √© um n√∫mero muito alto de erros do Tipo I.

* Falsos Negativos (FN): 124

O modelo previu que 124 pacientes n√£o sobreviveram, mas na verdade sobreviveram. Este √© um n√∫mero relativamente baixo de erros do Tipo II em compara√ß√£o com os Falsos Positivos.

* Verdadeiros Positivos (TP): 13394

O modelo previu que 13394 pacientes sobreviveram, e eles realmente sobreviveram. Este √© o maior n√∫mero na matriz.
Interpreta√ß√£o Preliminar:

O modelo parece ter uma forte tend√™ncia a prever que os pacientes sobreviver√£o (alto n√∫mero de Verdadeiros Positivos), mas tamb√©m comete muitos erros ao classificar pacientes que n√£o sobreviveram como sobreviventes (alt√≠ssimo n√∫mero de Falsos Positivos).

O n√∫mero de Verdadeiros Negativos √© muito baixo em compara√ß√£o com o n√∫mero de Falsos Positivos, indicando que o modelo tem dificuldade em identificar corretamente os pacientes que n√£o sobreviveram.

O n√∫mero de Falsos Negativos √© relativamente baixo, o que significa que o modelo n√£o erra tanto ao prever que um paciente que sobreviveu, na verdade n√£o sobreviveu.


#### 11. Avalia√ß√£o Abrangente do Modelo XGBoost para Sobreviv√™ncia com Valida√ß√£o Cruzada (Acur√°cia, Precis√£o, Recall e F1-Score Simultaneamente):
```python
from sklearn.model_selection import StratifiedKFold, cross_validate
# Importa as ferramentas necess√°rias para realizar a valida√ß√£o cruzada estratificada
# ('StratifiedKFold') e para avaliar o desempenho do modelo com m√∫ltiplas m√©tricas
# simultaneamente ('cross_validate') do scikit-learn.

from xgboost import XGBClassifier
# Importa a classe 'XGBClassifier' da biblioteca xgboost, que implementa o algoritmo de
# Gradient Boosting, um m√©todo poderoso para tarefas de classifica√ß√£o.

# Dados (X, y_survival j√° definidos)
# Este coment√°rio assume que voc√™ j√° preparou suas vari√°veis independentes ('X')
# e a vari√°vel dependente para sobreviv√™ncia ('y_survival'). 'X' deve conter as
# features para o modelo, e 'y_survival' deve conter os r√≥tulos de sobreviv√™ncia (e.g., 0 e 1).

# Modelo
modelo = XGBClassifier(objective='binary:logistic', random_state=42)
# Cria uma inst√¢ncia do classificador XGBoost.
# - 'objective='binary:logistic'': Especifica a fun√ß√£o objetivo para problemas de
#   classifica√ß√£o bin√°ria, que retornar√° probabilidades para as classes.
# - 'random_state=42': Define uma semente para o gerador de n√∫meros aleat√≥rios,
#   garantindo que os resultados sejam reproduz√≠veis.

# Estrat√©gia de Valida√ß√£o Cruzada
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# Cria uma inst√¢ncia da estrat√©gia de valida√ß√£o cruzada Stratified K-Fold.
# - 'n_splits=5': Define o n√∫mero de folds (partes) em que os dados ser√£o divididos.
#   Neste caso, ser√£o 5 folds.
# - 'shuffle=True': Embaralha os dados antes de dividi-los em folds para reduzir o
#   impacto da ordem dos dados.
# - 'random_state=42': Define uma semente para o embaralhamento, garantindo a
#   reprodutibilidade da divis√£o.
# O Stratified K-Fold mant√©m a propor√ß√£o das classes em cada fold, sendo ideal para
# conjuntos de dados potencialmente desbalanceados.

# Avaliando m√∫ltiplas m√©tricas com cross_validate
scoring = ['accuracy', 'precision', 'recall', 'f1']
# Define uma lista das m√©tricas que ser√£o avaliadas durante a valida√ß√£o cruzada:
# - 'accuracy': Propor√ß√£o de previs√µes corretas.
# - 'precision': Das previs√µes positivas, quantas foram realmente corretas (TP / (TP + FP)).
# - 'recall': De todas as inst√¢ncias positivas reais, quantas foram corretamente identificadas (TP / (TP + FN)).
# - 'f1': M√©dia harm√¥nica de precis√£o e recall, √∫til para equilibrar as duas m√©tricas.

resultados = cross_validate(modelo, X, y_survival, cv=stratified_kfold, scoring=scoring, return_train_score=False)
# Utiliza a fun√ß√£o 'cross_validate' para realizar a valida√ß√£o cruzada e avaliar m√∫ltiplas m√©tricas.
# - 'modelo': O classificador XGBoost a ser avaliado.
# - 'X': As features do conjunto de dados.
# - 'y_survival': A vari√°vel alvo de sobreviv√™ncia.
# - 'cv=stratified_kfold': Especifica a estrat√©gia de valida√ß√£o cruzada estratificada.
# - 'scoring=scoring': Define a lista de m√©tricas a serem calculadas.
# - 'return_train_score=False': Indica que n√£o queremos os scores no conjunto de treinamento.
# A fun√ß√£o retorna um dicion√°rio contendo arrays com os scores para cada m√©trica em cada fold.

print("Resultados da Valida√ß√£o Cruzada:")
# Imprime um cabe√ßalho para os resultados da valida√ß√£o cruzada.

print(f"Acur√°cia m√©dia: {resultados['test_accuracy'].mean():.4f}")
# Imprime a m√©dia da acur√°cia obtida nos diferentes folds. 'resultados['test_accuracy']'
# cont√©m um array com os scores de acur√°cia para cada fold. '.mean()' calcula a m√©dia.
# '{:.4f}' formata a sa√≠da para quatro casas decimais.

print(f"Precis√£o m√©dia: {resultados['test_precision'].mean():.4f}")
# Imprime a m√©dia da precis√£o obtida nos diferentes folds.

print(f"Recall m√©dio: {resultados['test_recall'].mean():.4f}")
# Imprime a m√©dia do recall obtido nos diferentes folds.

print(f"F1-Score m√©dio: {resultados['test_f1'].mean():.4f}")
# Imprime a m√©dia do F1-Score obtido nos diferentes folds.

Resultados da Valida√ß√£o Cruzada:
Acur√°cia m√©dia: 0.7441
Precis√£o m√©dia: 0.7487
Recall m√©dio: 0.9909
F1-Score m√©dio: 0.8529
```
##### Explica√ß√£o das M√©tricas de Avalia√ß√£o do Modelo de Sobreviv√™ncia (Valida√ß√£o Cruzada):

<p align="justify">As m√©tricas que voc√™ obteve atrav√©s da valida√ß√£o cruzada fornecem diferentes perspectivas sobre o desempenho do seu modelo XGBoost na tarefa de prever a sobreviv√™ncia (assumindo que a classe positiva seja "Sobreviveu"). Vamos detalhar cada uma delas:</p>

1. Precis√£o M√©dia (Valida√ß√£o Cruzada): 0.7487

<p align="justify">Serve para: Avaliar a qualidade das previs√µes positivas feitas pelo modelo. Especificamente, ela responde √† pergunta: "De todos os pacientes que o modelo previu que sobreviveriam, qual propor√ß√£o realmente sobreviveu?".
Fun√ß√£o: Calcula a m√©dia da precis√£o obtida em cada fold da valida√ß√£o cruzada. A precis√£o √© definida como:
Precis√£o = Verdadeiros Positivos (TP) / (Verdadeiros Positivos (TP) + Falsos Positivos (FP))
Verdadeiros Positivos (TP): Pacientes que realmente sobreviveram e foram corretamente previstos como sobreviventes.

<p align="justify">Falsos Positivos (FP): Pacientes que n√£o sobreviveram, mas foram incorretamente previstos como sobreviventes.
Interpreta√ß√£o: Uma precis√£o m√©dia de 0.7487 (ou 74.87%) sugere que, em m√©dia, cerca de 74.87% das vezes que o modelo previu que um paciente sobreviveria, essa previs√£o estava correta. Os restantes 25.13% das previs√µes de sobreviv√™ncia foram de pacientes que, na verdade, n√£o sobreviveram.

2. Recall M√©dio (Valida√ß√£o Cruzada): 0.9909

<p align="justify">Serve para: Avaliar a capacidade do modelo de encontrar todas as inst√¢ncias positivas reais. Em outras palavras, responde √† pergunta: "De todos os pacientes que realmente sobreviveram, qual propor√ß√£o o modelo conseguiu identificar corretamente?".</p>
     
<p align="justify"> Fun√ß√£o: Calcula a m√©dia do recall (tamb√©m conhecido como sensibilidade ou taxa de verdadeiros positivos) obtido em cada fold da valida√ß√£o cruzada. O recall √© definido como:</p>

<p align="justify">Recall = Verdadeiros Positivos (TP) / (Verdadeiros Positivos (TP) + Falsos Negativos (FN))
Falsos Negativos (FN): Pacientes que realmente sobreviveram, mas foram incorretamente previstos como n√£o sobreviventes.
Interpreta√ß√£o: Um recall m√©dio de 0.9909 (ou 99.09%) indica que, em m√©dia, o modelo conseguiu identificar corretamente aproximadamente 99.09% de todos os pacientes que realmente sobreviveram. Isso sugere uma alta sensibilidade do modelo para a classe "Sobreviveu", cometendo poucos erros ao classificar um paciente sobrevivente como n√£o sobrevivente.</p>

3. F1-Score M√©dio (Valida√ß√£o Cruzada): 0.8529

<p align="justify">Serve para: Fornecer uma m√©trica √∫nica que equilibra a precis√£o e o recall. √â especialmente √∫til quando h√° um desequil√≠brio entre as classes. O F1-Score tenta encontrar um bom compromisso entre a capacidade do modelo de n√£o rotular erroneamente a classe negativa como positiva (precis√£o) e sua capacidade de encontrar todas as inst√¢ncias positivas (recall).</p>

<p align="justify">Fun√ß√£o: Calcula a m√©dia do F1-Score obtido em cada fold da valida√ß√£o cruzada. O F1-Score √© a m√©dia harm√¥nica da precis√£o e do recall:</p>
<p align="justify">F1-Score = 2 * (Precis√£o * Recall) / (Precis√£o + Recall)
Interpreta√ß√£o: Um F1-Score m√©dio de 0.8529 (ou 85.29%) representa um bom equil√≠brio entre a precis√£o e o recall para a classe "Sobreviveu". Ele sugere que o modelo tem um desempenho razoavelmente bom tanto em n√£o fazer previs√µes falsas de sobreviv√™ncia quanto em identificar a maioria dos pacientes que realmente sobreviveram.</p>

4. Acur√°cia M√©dia (Valida√ß√£o Cruzada): 0.7441

<p align="justify">Serve para: Avaliar a propor√ß√£o geral de previs√µes corretas (tanto para a classe "Sobreviveu" quanto para a classe "N√£o Sobreviveu") em rela√ß√£o ao n√∫mero total de amostras. Responde √† pergunta: "De todos os pacientes no conjunto de dados, qual propor√ß√£o o modelo classificou corretamente?".</p>
     
<p align="justify">Fun√ß√£o: Calcula a m√©dia da acur√°cia obtida em cada fold da valida√ß√£o cruzada. A acur√°cia √© definida como:
Acur√°cia = (Verdadeiros Positivos (TP) + Verdadeiros Negativos (TN)) / (Total de Amostras)</p>
<p align="justify">FVerdadeiros Negativos (TN): Pacientes que realmente n√£o sobreviveram e foram corretamente previstos como n√£o sobreviventes.
Interpreta√ß√£o: Uma acur√°cia m√©dia de 0.7441 (ou 74.41%) indica que, em m√©dia, o modelo classificou corretamente cerca de 74.41% de todos os pacientes no conjunto de dados nos diferentes folds da valida√ß√£o cruzada.</p>

## Naive Bayes

<p align="justify">O Naive Bayes √© um algoritmo de classifica√ß√£o baseado no Teorema de Bayes com uma suposi√ß√£o "ing√™nua" de independ√™ncia entre as vari√°veis preditoras. Ele calcula a probabilidade de uma inst√¢ncia pertencer a uma determinada classe com base nas caracter√≠sticas observadas, assumindo que essas caracter√≠sticas s√£o estatisticamente independentes entre si.</p>

<p align="justify">O Naive Bayes √© amplamente utilizado por sua simplicidade, efici√™ncia e bom desempenho em v√°rias aplica√ß√µes, especialmente em classifica√ß√£o de texto. Ele se destaca pelas seguintes caracter√≠sticas:</p>

* **Baixo custo computacional**, com treinamento e previs√£o extremamente r√°pidos.  
* **Desempenho eficiente** mesmo em bases de dados com alta dimensionalidade.  
* **Funciona bem** com pequenos conjuntos de dados rotulados.  
* **Simples de implementar** e interpretar os resultados.  
* **Robustez** em problemas com ru√≠do e irrelev√¢ncia em algumas features.  
* **Aplica√ß√£o natural** em modelos probabil√≠sticos e an√°lise bayesiana.  
* **Suporte a diferentes varia√ß√µes**, como Bernoulli, Multinomial e Gaussiano, adaptando-se ao tipo de dado.  

### Estrat√©gias de Modelagem com Naive Bayes

<p align="justify">Foram implementadas e comparadas tr√™s abordagens distintas utilizando o classificador <strong>Naive Bayes</strong>:</p>

1. **Modelo Base (Sem Balanceamento)**  
   <p align="justify">Aplica√ß√£o direta do Naive Bayes no conjunto de dados original, sem qualquer t√©cnica de balanceamento das classes.</p>

2. **Naive Bayes com Oversampling (SMOTE)**  
   <p align="justify">Utiliza√ß√£o da t√©cnica de oversampling com <strong>SMOTE (Synthetic Minority Over-sampling Technique)</strong> para balancear as classes antes do treinamento do modelo.</p>

3. **Naive Bayes com Undersampling**  
   <p align="justify">Aplica√ß√£o da t√©cnica de <strong>undersampling</strong> utilizando o <strong>RandomUnderSampler</strong>, reduzindo a quantidade de amostras da classe majorit√°ria para equilibrar o conjunto de dados.</p>

<p align="justify">Cada uma dessas abordagens foi avaliada com base em m√©tricas de desempenho como <strong>acur√°cia</strong>, <strong>precis√£o</strong>, <strong>recall</strong>, <strong>F1-score</strong>, <strong>acur√°cia balanceada</strong> e <strong>G-mean</strong>, com o objetivo de entender os impactos das t√©cnicas de balanceamento na performance do modelo.</p>


### 1 - Naive Bayes sem balanceamento

#### 1.1 Prepara√ß√£o da Vari√°vel Alvo (target)


```python
target_var = 'Survival_Status'
y = df[target_var].copy()
if y.dtype == 'O':
    y = y.astype(str)
    y = y.map({label: idx for idx, label in enumerate(sorted(y.unique()))})
Define a vari√°vel alvo do modelo: Survival_Status.
```

<p align="justify"> Define a vari√°vel alvo do modelo: <code>Survival_Status</code>. Se a vari√°vel for categ√≥rica (<code>dtype == 'O'</code>), ela √© convertida para string e depois mapeada para n√∫meros (ex.: 'Sim' ‚Üí 1, 'N√£o' ‚Üí 0). Isso √© necess√°rio porque modelos do scikit-learn trabalham com n√∫meros. </p>

#### 1.2 Separa√ß√£o em treino e teste
```python
X_train, X_test, y_train, y_test = train_test_split(
    preprocessed_df, y, test_size=0.2, random_state=42, stratify=y
)
```

<p align="justify"> Divide os dados em treino (80%) e teste (20%), estratificando com base em <code>y</code>, para garantir que a propor√ß√£o de classes seja mantida nas duas amostras. <code>preprocessed_df</code> √© o conjunto de vari√°veis independentes (features), j√° pr√©-processado. </p>

preprocessed_df √© o conjunto de vari√°veis independentes (features), j√° pr√©-processado.

 #### 1.3 Treinamento do modelo Naive Bayes
```python
Copy
Edit
modelo = GaussianNB()
modelo.fit(X_train, y_train)
<p align="justify"> Cria um modelo <code>GaussianNB</code> (Naive Bayes Gaussiano, assume que os dados seguem uma distribui√ß√£o normal para cada atributo). Treina o modelo com os dados de treino. </p>

Treina o modelo com os dados de treino.

#### 1.4 Predi√ß√µes
```python
y_pred = modelo.predict(X_test)
y_prob = modelo.predict_proba(X_test)[:, 1] if len(modelo.classes_) == 2 else None
```
<p align="justify"> <code>y_pred</code>: Previs√µes de classe (0 ou 1). <code>y_prob</code>: Probabilidades da classe positiva (usado para ROC), somente se for um problema bin√°rio. </p>

#### 1.5 Relat√≥rio de M√©tricas
```python

print("\n=== Relat√≥rio de Classifica√ß√£o ===")
print(classification_report(y_test, y_pred))
```
<p align="justify"> Imprime precis√£o, recall, f1-score e suporte (n¬∫ de inst√¢ncias por classe), para cada classe. </p>

#### 1.6 C√°lculo e impress√£o de m√©tricas personalizadas
```python
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average='binary')
rec = recall_score(y_test, y_pred, average='binary')
f1 = f1_score(y_test, y_pred, average='binary')
bal_acc = balanced_accuracy_score(y_test, y_pred)
gmean_score = gmean([prec, rec]) if prec > 0 and rec > 0 else 0
```

<p align="justify"> Calcula diversas m√©tricas:<br> <strong>accuracy</strong>: Propor√ß√£o total de acertos.<br> <strong>precision</strong>: Quantos dos positivos previstos s√£o realmente positivos.<br> <strong>recall</strong>: Quantos dos positivos reais foram encontrados.<br> <strong>f1-score</strong>: M√©dia harm√¥nica entre precis√£o e recall.<br> <strong>balanced_accuracy</strong>: M√©dia entre a acur√°cia da classe positiva e negativa (evita vi√©s em classes desbalanceadas).<br> <strong>gmean</strong>: M√©dia geom√©trica entre precis√£o e recall (mede o equil√≠brio entre eles). </p>

#### 1.7 Impress√£o das m√©tricas
```python
print(f"Accuracy: {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall: {rec:.4f}")
print(f"F1-score: {f1:.4f}")
print(f"Balanced Accuracy: {bal_acc:.4f}")
print(f"Geometric Mean Accuracy: {gmean_score:.4f}")
```
<p align="justify"> Exibe todas as m√©tricas de forma formatada. </p>

 #### 1.8 Matriz de Confus√£o
```python
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=modelo.classes_, yticklabels=modelo.classes_)
```

<p align="justify"> Gera uma matriz de confus√£o mostrando:<br> <strong>Verdadeiros Positivos (VP)</strong><br> <strong>Falsos Positivos (FP)</strong><br> <strong>Verdadeiros Negativos (VN)</strong><br> <strong>Falsos Negativos (FN)</strong><br><br> Essa matriz mostra como o modelo est√° errando e acertando. </p>


#### 1.9 Curva ROC (caso bin√°rio)
```python
if y_prob is not None:
    fpr, tpr, thresholds = roc_curve(y_test, y_prob)
    auc_score = roc_auc_score(y_test, y_prob)
```

<p align="justify"> Calcula a curva ROC (True Positive Rate vs False Positive Rate) e √°rea sob a curva (AUC).<br> A AUC indica o poder discriminativo do modelo (quanto mais pr√≥ximo de 1.0, melhor). </p>

#### 1.10 Salvamento dos gr√°ficos
```python
plt.savefig("graphs/confusion_matrix_naive_bayes.png")
...
plt.savefig("graphs/roc_curve_naive_bayes.png")
```

<p align="justify"> Os gr√°ficos gerados s√£o salvos no diret√≥rio especificado para posterior an√°lise ou apresenta√ß√£o. </p>

### Resultados

#### Relat√≥rio de Classifica√ß√£o

| Classe | Precis√£o (Precision) | Revoca√ß√£o (Recall) | F1-Score | Suporte (Support) |
|--------|----------------------|--------------------|----------|-------------------|
| 0      | 0.00                 | 0.00               | 0.00     | 4521              |
| 1      | 0.75                 | 1.00               | 0.86     | 13468             |

**Acur√°cia Total**: 0.75  
**M√©dia Macro**:
- Precis√£o: 0.37
- Revoca√ß√£o: 0.50
- F1-Score: 0.43

**M√©dia Ponderada**:
- Precis√£o: 0.56
- Revoca√ß√£o: 0.75
- F1-Score: 0.64

#### M√©tricas Adicionais

- **Accuracy**: 0.7487  
- **Precision**: 0.7487  
- **Recall**: 1.0000  
- **F1-score**: 0.8563  
- **Balanced Accuracy**: 0.5000  
- **Geometric Mean Accuracy**: 0.8653  


<div align="center"> 
   <img src="https://github.com/user-attachments/assets/bdebaa8f-0d4b-4819-816c-7ffa7de50546" alt="Matriz de Confus√£o - Naive Bayes" width="500">
</div>

<div align="center"> 
   <img src="https://github.com/user-attachments/assets/5b3615f3-e559-48d7-a56b-0df88219e72b" alt="Curva ROC -  Naive Bayes" width="500"> 
</div>


<br>
<br>

---

### 2 - Descri√ß√£o do C√≥digo (Naive Bayes Oversampling) 

#### 2.1 Importa√ß√£o do SMOTE

```python
from imblearn.over_sampling import SMOTE
```

<p>O <strong>SMOTE (Synthetic Minority Over-sampling Technique)</strong> √© uma t√©cnica de oversampling que gera exemplos sint√©ticos para a classe minorit√°ria com base nos seus vizinhos mais pr√≥ximos. Essa abordagem √© √∫til para mitigar o problema de desbalanceamento de classes em conjuntos de dados.</p>


#### 2.2 Prepara√ß√£o das vari√°veis

```python
target_var = 'Survival_Status'
y = df[target_var].copy()
if y.dtype == 'O':
    y = y.astype(str)
    y = y.map({label: idx for idx, label in enumerate(sorted(y.unique()))})
```

<p>Seleciona a vari√°vel alvo <code>Survival_Status</code> e, se necess√°rio, realiza a convers√£o de valores categ√≥ricos para num√©ricos, facilitando o treinamento do modelo.</p>


#### 2.3 Divis√£o em treino e teste

```python
X_train, X_test, y_train, y_test = train_test_split(
    preprocessed_df, y, test_size=0.2, random_state=42, stratify=y
)
```

<p>Os dados s√£o divididos em treino e teste utilizando <code>train_test_split</code> com estratifica√ß√£o, o que garante a mesma propor√ß√£o de classes em ambos os conjuntos.</p>


#### 2.4 Aplica√ß√£o do SMOTE (Oversampling)

```python
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
```

<p>O SMOTE √© aplicado exclusivamente ao conjunto de treino para gerar amostras sint√©ticas da classe minorit√°ria, <strong>evitando vazamento de dados</strong> para o conjunto de teste.</p>

#### 2.5 Treinamento com Naive Bayes

```python
modelo = GaussianNB()
modelo.fit(X_train_resampled, y_train_resampled)
y_pred = modelo.predict(X_test)
y_prob = modelo.predict_proba(X_test)[:, 1] if len(modelo.classes_) == 2 else None
```

<p>O classificador <strong>Naive Bayes Gaussiano</strong> √© treinado com os dados balanceados e realiza a predi√ß√£o sobre o conjunto de teste. Quando o problema √© bin√°rio, tamb√©m √© calculada a probabilidade associada √† classe positiva.</p>


#### 2.6 Avalia√ß√£o do Modelo

```python
print(classification_report(y_test, y_pred))
```

M√©tricas principais:

- **Accuracy**: Propor√ß√£o de acertos.
- **Precision**: Precis√£o para a classe positiva.
- **Recall**: Sensibilidade (quantos positivos reais foram identificados).
- **F1-score**: M√©dia harm√¥nica entre precis√£o e recall.
- **Balanced Accuracy**: M√©dia entre sensitividade e especificidade.
- **Geometric Mean (gmean)**: M√©dia geom√©trica entre precis√£o e recall.


#### 2.7 Matriz de Confus√£o

```python
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
```

<p>A <strong>matriz de confus√£o</strong> permite avaliar visualmente os acertos e erros do modelo, separando verdadeiros e falsos positivos/negativos.</p> <p align="center"> <img src="https://github.com/user-attachments/assets/cca27b0e-1a0f-49b4-ba46-4f23afd98469" width="500"> </p>

#### 2.8 Curva ROC e AUC

```python
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)
```

<p>A <strong>curva ROC</strong> relaciona a taxa de verdadeiros positivos (TPR) com a taxa de falsos positivos (FPR), e a <strong>AUC</strong> representa a capacidade do modelo em distinguir entre as classes.</p> <p align="center"> <img src="https://github.com/user-attachments/assets/44f124c2-0320-4de4-a484-548f4ee7b660" width="500"> </p>

### Resultados: Relat√≥rio de Classifica√ß√£o

#### M√©tricas por Classe

| Classe | Precis√£o (`precision`) | Revoca√ß√£o (`recall`) | F1-score | Suporte |
|--------|------------------------|-----------------------|----------|---------|
| 0      | 0.25                   | 0.52                  | 0.34     | 4,521   |
| 1      | 0.75                   | 0.48                  | 0.58     | 13,468  |

#### M√©dias Globais

| Tipo de M√©dia   | Precis√£o | Revoca√ß√£o | F1-score | Suporte |
|-----------------|----------|-----------|----------|---------|
| Macro m√©dia     | 0.50     | 0.50      | 0.46     | 17,989  |
| M√©dia ponderada | 0.62     | 0.49      | 0.52     | 17,989  |

#### M√©tricas Agregadas

| M√©trica                  | Valor   |
|--------------------------|---------|
| Acur√°cia (`accuracy`)    | 0.4889  |
| Precis√£o (classe 1)      | 0.7490  |
| Revoca√ß√£o (classe 1)     | 0.4774  |
| F1-score (classe 1)      | 0.5831  |
| Acur√°cia Balanceada      | 0.5003  |
| Geometric Mean Accuracy  | 0.5979  |

<br>
<br> 

### 3 - Descri√ß√£o do C√≥digo (Naive Bayes Undersampling) 

<p align="center"> Este experimento visa desenvolver um modelo de classifica√ß√£o para a vari√°vel <code>Survival_Status</code> utilizando a t√©cnica de balanceamento por Undersampling. Para isso, foi empregada a biblioteca <code>imblearn</code> e o classificador probabil√≠stico <code>GaussianNB</code>, considerando um conjunto de dados originalmente desbalanceado.</p>


#### 3.1  Convers√£o da Vari√°vel Alvo

```python
target_var = 'Survival_Status'
y = df[target_var].copy()
if y.dtype == 'O':
    y = y.astype(str)
    y = y.map({label: idx for idx, label in enumerate(sorted(y.unique()))})
```
<p align="center"> A vari√°vel-alvo <code>Survival_Status</code> √© copiada do DataFrame principal. Caso seus valores sejam do tipo <code>object</code> (strings), realiza-se a codifica√ß√£o de r√≥tulos (label encoding), atribuindo valores num√©ricos distintos para cada categoria. Essa transforma√ß√£o √© fundamental, pois os algoritmos de machine learning n√£o operam diretamente com dados categ√≥ricos. </p>

#### 3.2 Divis√£o dos Dados com Estratifica√ß√£o

```python
X_train, X_test, y_train, y_test = train_test_split(
    preprocessed_df, y, test_size=0.2, random_state=42, stratify=y
)
```

#### 3.3 Aplica√ß√£o de Undersampling

```python
under = RandomUnderSampler(random_state=42)
X_train_resampled, y_train_resampled = under.fit_resample(X_train, y_train)
```
<p align="center"> O <code>RandomUnderSampler</code> √© aplicado apenas ao conjunto de treino. Ele reduz aleatoriamente o n√∫mero de amostras da classe majorit√°ria at√© que haja equil√≠brio entre as classes. Essa t√©cnica combate o vi√©s que o modelo poderia desenvolver ao priorizar a classe mais frequente. </p>


#### 3.4 Treinamento do Modelo com Naive Bayes

```python
modelo = GaussianNB()
modelo.fit(X_train_resampled, y_train_resampled)
```

#### 3.5 Predi√ß√£o e C√°lculo das Probabilidades

```python
y_pred = modelo.predict(X_test)
y_prob = modelo.predict_proba(X_test)[:, 1] if len(modelo.classes_) == 2 else None
```

#### 3.6 Avalia√ß√£o do Modelo

```python
print(classification_report(y_test, y_pred))
```
<p align="center"> A avalia√ß√£o inclui a gera√ß√£o do relat√≥rio de classifica√ß√£o com m√©tricas como precis√£o, recall e f1-score. Adicionalmente, m√©tricas agregadas s√£o calculadas manualmente, fornecendo uma an√°lise mais abrangente. </p>

```python
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average='binary')
rec = recall_score(y_test, y_pred, average='binary')
f1 = f1_score(y_test, y_pred, average='binary')
bal_acc = balanced_accuracy_score(y_test, y_pred)
gmean_score = gmean([prec, rec]) if prec > 0 and rec > 0 else 0
```

#### 3.7 Matriz de Confus√£o

```python
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Oranges')
```
<p align="center"> A matriz de confus√£o mostra a distribui√ß√£o dos acertos e erros do modelo. Essa visualiza√ß√£o √© crucial para entender o comportamento do classificador em contextos desbalanceados. </p> <p align="center"> <img src="https://github.com/user-attachments/assets/eed9f502-e0b4-47a1-9960-797ddd367f3f" alt="Matriz de Confus√£o" width="500"> </p>


#### 3.8 Matriz de Confus√£o

```python
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)
```

<p align="center"> A curva ROC demonstra a capacidade do modelo em distinguir entre classes positivas e negativas. A AUC (√°rea sob a curva) √© um indicador da qualidade geral do classificador ‚Äî quanto mais pr√≥xima de 1, melhor. </p> <p align="center"> <img src="https://github.com/user-attachments/assets/5588379b-10a8-43e0-aee2-bd61a5126475" alt="Curva ROC" width="500"> </p>


### Resultados:

#### Relat√≥rio de Classifica√ß√£o
| Classe         | Precision | Recall | F1-score | Support |
|----------------|-----------|--------|----------|---------|
| 0              | 0.26      | 0.61   | 0.36     | 4521    |
| 1              | 0.76      | 0.41   | 0.53     | 13468   |
| **Accuracy**   |           |        | 0.46     | 17989   |
| Macro avg      | 0.51      | 0.51   | 0.44     | 17989   |
| Weighted avg   | 0.63      | 0.46   | 0.49     | 17989   |

| M√©trica                  | Valor   |
|--------------------------|---------|
| Accuracy                 | 0.4572  |
| Precision (Classe 1)     | 0.7568  |
| Recall (Classe 1)        | 0.4051  |
| F1-score (Classe 1)      | 0.5277  |
| Balanced Accuracy        | 0.5087  |
| Geometric Mean Accuracy  | 0.5537  |


<br>
<br> 

---


###  Resumo das Tr√™s Abordagens com Naive Bayes

| Estrat√©gia         | Accuracy | Precision | Recall  | F1-score | Balanced Accuracy | Geometric Mean |
|--------------------|----------|-----------|---------|----------|--------------------|----------------|
| üîµ Sem Balanceamento | 0.7487   | 0.7487    | 1.0000  | 0.8563   | 0.5000             | 0.8653         |
| üü¢ Oversampling      | 0.4889   | 0.7490    | 0.4774  | 0.5831   | 0.5003             | 0.5979         |
| üî¥ Undersampling     | 0.4572   | 0.7568    | 0.4051  | 0.5277   | 0.5087             | 0.5537         |

---

####  Interpreta√ß√£o das M√©tricas

### üîµ Sem Balanceamento (Naive Bayes Puro)

- **Precision = 0.7487** ‚Üí O modelo acerta bem quando prev√™ sobreviv√™ncia (classe 1).
- **Recall = 1.0000** ‚Üí Identificou *todos* os pacientes sobreviventes.
- **F1-score = 0.8563** ‚Üí Excelente equil√≠brio entre precis√£o e recall.
- **Balanced Accuracy = 0.5000** ‚Üí Mostra que a classe 0 (n√£o sobreviveu) est√° sendo ignorada.
-  **Confus√£o**: o modelo classificou todos os casos como classe 1.

 **Conclus√£o**:  
O modelo adota uma estrat√©gia conservadora, classificando todos os casos como sobreviventes. Embora essa abordagem possa parecer eficaz para triagens iniciais, **ela falha completamente na identifica√ß√£o dos indiv√≠duos que n√£o sobrevivem**, o que pode representar um **risco significativo em contextos m√©dicos**.

---

### üü¢ Com Oversampling (SMOTE)

- **Precision = 0.7490**
- **Recall = 0.4774**
- **F1-score = 0.5831**
- **G-Mean = 0.5979**
- **Balanced Accuracy = 0.5003**

 **Conclus√£o**:  
A t√©cnica SMOTE contribuiu para que o modelo **reconhecesse ambas as classes**, preservando todas as amostras originais e atenuando o desbalanceamento dos dados. Embora ainda existam erros, o modelo demonstra maior equidade na previs√£o das classes.

---

### üî¥ Com Undersampling

- **Recall = 0.4051**
- **Precision = 0.7568**
- **F1-score = 0.5277**
- **G-Mean = 0.5537**

**Conclus√£o**:  
A remo√ß√£o de dados da classe majorit√°ria resultou em desempenho inferior. **Reduzir a quantidade de dados implica perda de informa√ß√£o**, o que dificulta o processo de aprendizado do modelo.

---

###  Qual foi o melhor resultado?

| Objetivo Priorit√°rio                               | Melhor Estrat√©gia                         |
|----------------------------------------------------|--------------------------------------------|
| M√°xima detec√ß√£o de sobreviventes (Recall)          | ‚úÖ Sem balanceamento (Recall = 1.00)        |
| Equil√≠brio entre as classes                        | üü¢ Oversampling (melhor G-Mean e Balance)  |
| Preservar todos os dados                           | üü¢ Oversampling (mant√©m todas as inst√¢ncias)|

---


# Avalia√ß√£o dos modelos criados

## M√©tricas utilizadas

<p align="justify">As m√©tricas calculadas foram Acur√°cia (percentual de previs√µes corretas no total), Precis√£o (qu√£o correto o modelo foi ao prever a sobreviv√™ncia), Recall (quantidade de casos de sobreviv√™ncia corretamente identificados) e F1-Score (harmoniza√ß√£o entre Precis√£o e Recall). De modo geral, os valores de Acur√°cia e F1-Score mantiveram-se bastante elevados para todos os modelos, com destaque para o Naive Bayes, que apresentou recall de 100% em todas as divis√µes dos dados, enquanto Random Forest e XGBoost tiveram uma leve queda de desempenho conforme a propor√ß√£o de teste aumentava.</p>

## Discuss√£o dos resultados obtidos

<p align="justify">Analisando os resultados gerais, os tr√™s modelos obtiveram desempenhos muito bons, com pequenas varia√ß√µes entre eles conforme o volume de dados de teste aumentava. O Random Forest e o XGBoost apresentaram uma pequena perda de desempenho em termos de precis√£o e F1-Score √† medida que a porcentagem de teste aumentava. J√° o Naive Bayes se destacou pela consist√™ncia: manteve precis√£o, recall e F1-Score elevados (pr√≥ximos de 1.0) em todas as divis√µes de treino/teste, sem apresentar erros (falsos positivos ou falsos negativos) nos dados de valida√ß√£o. Com base nos resultados apresentados, o Naive Bayes foi o m√©todo que apresentou o melhor desempenho geral, demonstrando tanto alta capacidade de identifica√ß√£o dos sobreviventes quanto estabilidade nas diferentes propor√ß√µes de divis√£o dos dados.</p>

# Pipeline de pesquisa e an√°lise de dados

Em pesquisa e experimenta√ß√£o em sistemas de informa√ß√£o, um pipeline de pesquisa e an√°lise de dados refere-se a um conjunto organizado de processos e etapas que um profissional segue para realizar a coleta, prepara√ß√£o, an√°lise e interpreta√ß√£o de dados durante a fase de pesquisa e desenvolvimento de modelos. Esse pipeline √© essencial para extrair _insights_ significativos, entender a natureza dos dados e, construir modelos de aprendizado de m√°quina eficazes. 

# V√≠deo de apresenta√ß√£o da Etapa 03

